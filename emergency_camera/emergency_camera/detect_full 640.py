import cv2
import time
from ultralytics import YOLO

# =========================================================
# [ì„¤ì •] ì‚¬ìš©ì ì •ì˜ ë³€ìˆ˜
# =========================================================
MODEL_PATH = "pt_data/result8.pt" 
CAM1_IDX = 3
CAM2_IDX = 2

# =========================================================
# 1. ëª¨ë¸ ë¡œë“œ
# =========================================================
print(f"[{MODEL_PATH}] ëª¨ë¸ ë¡œë”© ì¤‘...")
model = YOLO(MODEL_PATH)

# =========================================================
# 2. ì¹´ë©”ë¼ ì—°ê²° (ì˜ˆì™¸ ì²˜ë¦¬ ì ìš©)
# =========================================================
print("ì¹´ë©”ë¼ ì—°ê²° ì‹œë„ ì¤‘...")

# í™œì„±í™”ëœ ì¹´ë©”ë¼ë¥¼ ê´€ë¦¬í•  ë¦¬ìŠ¤íŠ¸
active_caps = []

# í•¨ìˆ˜: ì¹´ë©”ë¼ ì—°ê²° ì‹œë„ ë° ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
def try_connect_camera(idx, name):
    cap = cv2.VideoCapture(idx)
    if cap.isOpened():
        print(f"âœ… {name} ì—°ê²° ì„±ê³µ")
        return {'cap': cap, 'name': name}
    else:
        print(f"âš ï¸ {name} ì—°ê²° ì‹¤íŒ¨ (ê±´ë„ˆëœ€)")
        return None

# ê°ê° ì—°ê²° ì‹œë„
cam1_info = try_connect_camera(CAM1_IDX, "Camera 2")
if cam1_info: active_caps.append(cam1_info)

cam2_info = try_connect_camera(CAM2_IDX, "Camera 4")
if cam2_info: active_caps.append(cam2_info)

# ì—°ê²°ëœ ì¹´ë©”ë¼ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì¢…ë£Œ
if not active_caps:
    print("âŒ ì—°ê²°ëœ ì¹´ë©”ë¼ê°€ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
    exit()

print(f"ğŸš€ ì´ {len(active_caps)}ëŒ€ ì¹´ë©”ë¼ë¡œ ì‹¤ì‹œê°„ ì¶”ë¡  ì‹œì‘! (ì¢…ë£Œ: 'q')")

# =========================================================
# 3. ì‹¤ì‹œê°„ ë£¨í”„
# =========================================================
prev_time = 0

while True:
    frames = []
    valid_caps_info = [] # ì´ë²ˆ í”„ë ˆì„ì—ì„œ ì½ê¸° ì„±ê³µí•œ ì¹´ë©”ë¼ ì •ë³´

    # -----------------------------------------------------
    # [ì½ê¸°] í™œì„±í™”ëœ ì¹´ë©”ë¼ë“¤ë§Œ ë£¨í”„ ëŒë©° í”„ë ˆì„ ìˆ˜ì§‘
    # -----------------------------------------------------
    for cam_info in active_caps:
        ret, frame = cam_info['cap'].read()
        if ret:
            frames.append(frame)
            valid_caps_info.append(cam_info)
        else:
            # ì¼ì‹œì  ëŠê¹€ í˜¹ì€ ì—°ê²° í•´ì œ ì‹œ ê·¸ëƒ¥ íŒ¨ìŠ¤ (í”„ë¡œê·¸ë¨ ì•ˆ ì£½ìŒ)
            pass

    # ë§Œì•½ ëª¨ë“  ì¹´ë©”ë¼ì—ì„œ í”„ë ˆì„ì„ ëª» ë°›ì•˜ë‹¤ë©´ ì¢…ë£Œ í˜¹ì€ ëŒ€ê¸°
    if not frames:
        print("ëª¨ë“  ì¹´ë©”ë¼ í”„ë ˆì„ ìˆ˜ì‹  ì‹¤íŒ¨ (ì¬ì‹œë„ ì¤‘...)")
        if cv2.waitKey(1) & 0xFF == ord('q'): break
        continue

    # -----------------------------------------------------
    # [ì¶”ë¡ ] ìˆ˜ì§‘ëœ í”„ë ˆì„ ì¼ê´„ ì¶”ë¡  (Batch Inference)
    # -----------------------------------------------------
    # ê¸°ë³¸ ì„¤ì • ìœ ì§€ (imgsz ìë™, conf ê¸°ë³¸ê°’)
    results = model(frames, verbose=False)

    # -----------------------------------------------------
    # [ì‹œê°í™”] ê²°ê³¼ ê·¸ë¦¬ê¸° ë° FPS í‘œì‹œ
    # -----------------------------------------------------
    display_frames = []
    
    # FPS ê³„ì‚°
    curr_time = time.time()
    fps = 1 / (curr_time - prev_time) if prev_time != 0 else 0
    prev_time = curr_time

    for i, res in enumerate(results):
        # ê²°ê³¼ ì´ë¯¸ì§€ ìƒì„±
        res_plot = res.plot()
        
        # ì¹´ë©”ë¼ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        cam_name = valid_caps_info[i]['name']

        # í…ìŠ¤íŠ¸ ì¶”ê°€
        cv2.putText(res_plot, f"FPS: {fps:.1f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 
                    1, (0, 255, 0), 2, cv2.LINE_AA)
        cv2.putText(res_plot, cam_name, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 
                    0.7, (255, 255, 255), 2)
        
        display_frames.append(res_plot)

    # -----------------------------------------------------
    # [í™”ë©´ ë³‘í•© ë° ì¶œë ¥] ê°œìˆ˜ì— ë”°ë¼ ìœ ë™ì ìœ¼ë¡œ ì²˜ë¦¬
    # -----------------------------------------------------
    if len(display_frames) == 1:
        # ì¹´ë©”ë¼ê°€ 1ëŒ€ë§Œ ì‘ë™ ì¤‘ì¼ ë•Œ
        cv2.imshow("Real-time Inference", display_frames[0])
        
    elif len(display_frames) >= 2:
        # ì¹´ë©”ë¼ê°€ 2ëŒ€ ì´ìƒì¼ ë•Œ ê°€ë¡œ ë³‘í•©
        try:
            combined_frame = cv2.hconcat(display_frames)
            cv2.imshow("Real-time Inference", combined_frame)
        except Exception as e:
            print(f"í™”ë©´ ë³‘í•© ì˜¤ë¥˜: {e}")

    # 'q' í‚¤ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ì¢…ë£Œ ì •ë¦¬
for cam_info in active_caps:
    cam_info['cap'].release()
cv2.destroyAllWindows()
print("í”„ë¡œê·¸ë¨ ì¢…ë£Œ")